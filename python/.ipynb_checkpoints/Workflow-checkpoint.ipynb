{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CI/CD\n",
    "\n",
    "***Continuous integration***: L'intégration continue est une pratique de développement consistant à intégrer ses développements le plus souvent possible à la *codebase*. Le principal objectif de cette pratique est d'éviter les énormes conflits qui apparaissent souvent lorsqu'on doit réconcillier deux branches existant depuis longtemps (*merge hell*). En poussant à intégrer son travail le plus souvent possible au *master*, aucune branche ne peut significativement diverger et créer des conflits à résoudre. On peut résumer cette idée contre-intuitive (il peut légitimement apparaître risquer d'augmenter la fréquence des modification du *master*) par la formule: \"*If it hurts, do it more often*\". Certes on intègre des changements plus fréquemment mais ceux-ci sont plus petits, les éventuels conflits et bugs qu'ils peuvent amener seront donc vraisemblablement plus simples et rapides à résoudre. Augmenter la fréquence d'intégration au *master* (jusqu'à plusieurs dizaines de fois par jour) c'est aussi augmenter la fréquence à laquelle des éléments du projet risquent de casser même si ces problèmes sont plus simples. Pour éviter de remplacer un problème par un autre, l'intégration continue présuppose ainsi l'existence d'une bonne couverture de tests et l'automatisation de ceux-ci. Le service de CI surveille ainsi tout changement intervenant sur la *codebase*. Quand il détecte un changement, il récupère le nouvel état du code et lance un *build* et les tests. En cas d'échec les développeurs sont notifiés. En cas de succès on remarque que la CI nous permet d'avoir en permanence un *build* de la toute dernière version du code (potentiellement pratique pour l'équipe de testeurs).\n",
    "\n",
    "On remarque que le passage à la CI présuppose un changement dans les pratiques de développement au sens où les développeurs sont obligés de découper finement leur travail.\n",
    "\n",
    "Pour Jez Humble, on ne fait réellement de la CI que si les trois critères suivants sont remplis: \n",
    "* Le travail de chaque développeur est intégré au moins une fois par jour au *master*,\n",
    "* Il existe une chaîne de tests nous permettant de pouvoir affirmer avec confiance que déployer notre code présente un minimum de risque pour la production,\n",
    "* Réactivité: si le code déployé casse en production, celle-ci est réparée en 10-20min: un problème en production devient instantanément la priorité numéro un de l'équipe.\n",
    "\n",
    "***Continuous delivery***: La *continuous delivery* prend sa source dans un des principes énoncés par l'*Agile Manifesto* qui exprime qu'un projet de développement doit viser à la *customer satisfaction by early and continuous delivery of valuable software*: Si une fonctionnalité ayant une valeur pour le client est prête, elle doit être livrée voire déployée en production (cf. *continuous deployment*). Une fois apportés des changements au code qui ont une valeur pour le client, comment apporter ce nouvel état de la *codebase* à un status de *Ready to deploy* ? C'est la problématique qu'adresse la *continuous delivery* en soumettant notamment le nouvel état du code à une série de tests de plus en plus difficiles. On se réfère à cette série de tests comme une *deployment pipeline*.\n",
    "\n",
    "Une chaîne de CD consiste en une chaîne d'environnements de tests qui idéalement se rapprochent de plus en plus des conditions de la production et de procédures d'automatisation permettant:\n",
    "1. De déployer automatiquement notre code dans un environnement de test\n",
    "2. De réaliser automatiquement un certain nombre de tests dans cet environnement\n",
    "3. De déployer dans l'environnement de test suivant si un certain nombre de conditions sont satisfaites.\n",
    "\n",
    "Idéalement le dernier environnement de test est un miroir ou au minimum très proche de l'environnement de production. A l'issue de cette chaîne de tests, le code évalué doit pouvoir être jugé assez fiable pour aller en production. Une chaîne de CD adéquate doit pouvoir nous amener à ce degré de confiance.\n",
    "\n",
    "La chaîne de CD se déclenche typiquement si la CI a réussi (*build* + tests) et donc à sa suite: les sources *buildées* par la CI sont automatiquement déployées et testées dans les différents environnements de tests par la CD. La CI va en fait de pair avec la CD: faire confiance à son code et réagir à des incidents est d'autant plus facile que les incréments sont petits. Le corrolaire de la fréquence à laquelle le code est modifié est l'automatisation de toute la chaîne de *build* et de test.\n",
    "\n",
    "La CD repose en grande partie sur de l'automatisation dont la mise en place présuppose un solide *configuration management*. Tout doit être versionné: schémas de base de donnée, scripts de déploiement, scripts de configuration de serveurs, etc. Ce faisant, en cas de rupture de la production on est capable de rapidement identifier le changement responsable et le corriger ou revenir en arrière.\n",
    "\n",
    "Au fond quels sont les bénéfices de la CD ?\n",
    "* *Small changes, lower deployment risk*: les changements sont plus petits. Le problème est plus rapidement identifié et corrigé. Au pire on peut *rollback*.\n",
    "* *Definition of Done*: On peut davantage affirmer avec confiance que des progrès on été réalisé quand les développeurs disent *It's deployed live* que *I'm done*. \n",
    "* *Quick user feedback*: On apprend en déployant en production. On peut demander autant qu'on veut à l'utilisateur ce qu'il désire mais ce n'est que quand on lui donne finalement quelque chose qu'on saura ce qu'il ne veut pas.\n",
    "\n",
    "**Continuous deployment**: Le terme de *continuous deployment* doit s'entendre comme *continuous deployment to production*. Il s'agit de l'idée que dès qu'une fonctionnalité est intégrée à la *codebase* elle est, si elle passe l'ensemble des tests de la chaîne de CI/CD, directement et automatiquement (sans intervention humaine) déployée en production. \n",
    "\n",
    "Minimiser les risques d'une telle pratique exige une très bonne couverture de tests. On peut aussi ne déployer le nouveau code que sur un *canary server*: seule une partie de la charge est dirigée vers le nouveau code. Le *continuous deployment* va de pair avec les pratiques de la CI. Cela permet notamment de faire le pari que même si on casse quelque chose, réparer sera simple et rapide du fait que la *codebase* n'est modifiée que par petits incréments.\n",
    "\n",
    "L'idée de déployer aussi souvent est d'avoir un *feedback* rapide des utilisateurs. \n",
    "\n",
    "Le *continuous deployment* est une forme extrême de *continuous delivery*: il s'agit simplement d'une chaîne de CD où on automatise en plus le déploiement du dernier environnement de test à la production. Toutes les entreprises ne sautent pas le pas. On peut en effet légitimement considérer que le déploiement en production (le moment et les fonctionnalités qu'on enbarque) est une décision métier et non technique.\n",
    "\n",
    "L'idée sous-jacente derrière ces trois pratiques est que si on a confiance dans notre code (notamment parce qu'on pense nos tests suffisamment nombreux et bien conçus), rien ne nous retient de le déployer.\n",
    "\n",
    "Questions: En cas d'échec du build/tests, le changement est quand même intégré ? La chaîne de CI intervient quand ? à la PR ou on merge et on verra après ? Où s'intègre la code review ?  \n",
    "Scaling: Si chaque étape de build/tests prend 5min, pas sûr qu'on puisse avoir 15 développeurs mergeant 5 fonctionnalités par jour. \n",
    "A la CI/CD est attachée une workflow strategy (workflow git)\n",
    "Organisation du code: qu'est ce qu'on versionne ensemble (tout ce qui partage un même cycle de vie) ? A quelle moment on versionne: si CI, on versionne pas/update pas le changelog à chaque fois ?\n",
    "Impact sur le branching model ?\n",
    "Quand on le choisit: \n",
    "* How often do we release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "Version du code/configs\n",
    "Version des données \n",
    "Version des modèles\n",
    "Problèmes de compatibilités/de dépendances entre les différentes entités versionnées\n",
    "Métriques/monitoring: Quelles métriques/comment on évalue la perf d'un modèle en live/créé le feedback utilisateur? Stack de monitoring\n",
    "Quels outils ? Qu'est ce qu'il se fait ailleurs ?\n",
    "Quelles sont les problématiques (gérer les artéfacts, monitoring, réentrainement) ?\n",
    "Entrainement peut se voir comme l'analogue du build pour les modèles.\n",
    "\n",
    "https://developers.google.com/machine-learning/guides/rules-of-ml\n",
    "\n",
    "Trois temps du ML\n",
    "Development \n",
    "Deployment\n",
    "Operation\n",
    "\n",
    "Tests en ML ? Monitoring, diagnostics, rollback, rebuilding strategies en ML ?\n",
    "\n",
    "Data validation: traiter un problème de données aussi sérieusement qu'un bug\n",
    "\n",
    "Problème: Le training set n'est qu'une approximation de la réalité à un instant t. Les données peuvent évoluer et la performance d'un modèle se dégrader au cours du temps.\n",
    "\n",
    "Online learning: On réentraine quasiment à chaque arrivée de nouvelles données ou très régulièrement. Présuppose: \n",
    "* Qu'on a accès à la ground truth quasiment en même temps de l'arrivée de nouvelles données\n",
    "* Exige davantage de monitoring pour éviter que les modèles ne prennent pas une mauvaise trajectoire\n",
    "* Potentiellement coûteux pour les gros modèles\n",
    "* Peut nécessiter de séparer infrastructure d'inférence et d'entraînement.\n",
    "\n",
    "Active learning: Approche différente dans le sens où on laisse le modèle prédire, demande une labellisation pour les observations pour lesquels sa prédiction est la moins sûre et ajoute ces nouvelles paires labellisées au training set. Approche particulièrement utile car on vient affiner là où le modèle est le moins bon, c'est à dire proche de la frontière de décision.\n",
    "\n",
    "Model monitoring: what to monitor ? \n",
    "* Input data: \n",
    "    * Données structurées (statisques descriptives, KL divergence, Heillinger distance), \n",
    "    * Images (contraste, luminosité, etc.)\n",
    "    * Etc.\n",
    "* Features: Distribution des features change, importance relative des features change\n",
    "* Model outputs: \n",
    "    * Prediction distribution mais attention pas toujours simple. Par ex: impact du comportement utilisateur: les utilisateurs n'uploadent que des images d'avions.\n",
    "    * Model confidence\n",
    "    * Comparaison avec les prédictions d'autres modèles\n",
    "    * Comparaison avec la ground truth si disponible\n",
    "\n",
    "Diagnostics: on observe une dégradation de la performance, d'où cela provient-il ? Bug dans le feature engineering ? Quelqu'un a déployé un nouveau modèle ? Où est la version d'avant si on souhaite rollback ? On a une métrique de performance du modèle qui s'effondre: pourquoi ? \n",
    "\n",
    "Exemples de changements dans les données d'entrée:\n",
    "* Données structurées - Changements de schémas: noms de colonne qui change, champs supplémentaires ou manquants, changement de types, valeurs interdites (ex: on peut dire qu'une colonne n'est pas nullable car le modèle ne prend pas en charge ces valeurs mais des données arrivent avec des NaN/NA). Contrôler ces éléments fait partie de l'étape de validation des données.\n",
    "\n",
    "Tests act as a documentation: ils permettent d'incorporer de la connaissance métier sur l'objet testé à la code base.\n",
    "\n",
    "Plus difficile que la validation, contrôler la présence d'un éventuel dataset shift/drift:\n",
    "* Input drift: Différence de distribution pour une même variable entre le training set et inference set. N'implique pas forcément une chute de la performance du modèle.\n",
    "* Concept drift: La fonction à apprendre a changé, va se manifester par une chute de la performance du modèle. Il existe une variété de tests visant à l'évaluer (Drift Detection Method - DDM, Early Drift Detection Method - EDDM, Linear Four Rates - LFR, etc.) Cf. https://www.youtube.com/watch?v=woRmeGvOaz4\n",
    "\n",
    "Différentes méthodes de détection de drift pour différentes situations. Ex: drifts brutaux vs. graduels\n",
    "\n",
    "Validation/Tests/Monitoring des données d'entrée: peut être coûteux, on peut ne pas voulois que le reste de la pipeline en dépende: sidecar/async architecture. La validation est alors en fait une branche de notre pipeline. \n",
    "\n",
    "Monitoring: service séparé qui se fait notifier par l'inférence service par ex.\n",
    "\n",
    "Quand est-ce qu'on reentraine: si la distribution n'a pas changé et la performance est stable, pas de raison même si on a beaucoup d'historique supplémentaire.\n",
    "\n",
    "Quand la ground truth n'est pas accessible tout de suite? Ou partiellement accessible (ex: credit default: on ne pourra jamais savoir si un dossier rejeté aurait finalement fait défaut ou non). On peut labelliser à la main. On peut comparer à l'output d'autres modèles (weak supervision).\n",
    "\n",
    "A/B Testing\n",
    "\n",
    "Active learning/online learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
