{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données déséquilibrées\n",
    "Dans la pratique, les problèmes de classification qu'ils soient bianires ou multiclasses se retrouvent face à des *datasets* déséquilibrés où une ou plusieurs classes sont présentes en effectifs sensiblement inférieur comparé à la ou les classes majoritaires. Dans la suite de ce document, on se place dans le cas de la classification binaire où un jeu de donné se répartit entre une classe dite majoritaire et une autre classe dite minoritaire.\n",
    "\n",
    "Un fort déséquilibre des classes pose différents problèmes aux méthodes de classification supervisée. Par exemple:\n",
    "* Les algorithmes font généralement l'hypothèse que les deux classes sont équilibrées (dit autrement, les erreurs faites par l'algorithme ne sont pas pondérés différemment suivant la classe). Si ce n'est pas le cas, il faut que le modèle en tienne compte (en général en introduisant une pondération à certain un moment de la procédure d'entraînement) sous peine d'obtenir un modèle en général biaisé en faveur de la classe majoritaire.\n",
    "* Mauvaise performances en généralisation: si l'effectif de la classe minoritaire est trop faible, il risque de juste ne pas être possible d'apprendre une \"bonne\" frontière de décision (d'autant plus vrai que la dimensionnalité est élevée).\n",
    "* Contraintes en validation et instabilité/incertitude et significativité des métriques: si l'effectif de la classe minoritaire est trop faible, on risque d'avoir trop peu de représentants de celle-ci dans chaque *fold* de la *cross-validation* avec pour conséquence un apprentissage et des métriques de performance instables.\n",
    "* Certaines métriques deviennent inadaptées car faisant implicitement l'hypothèse d'un *dataset* équilibré : la classe minoritaire y contribue donc très peu et risque donc d'être négligée par l'algorithme qui va se biaiser en faveur de la classe majoritaire. Ex: l'*accuracy*. Dans le cas d'un *dataset* déséquilibré à 99/1 pour les classes 0/1, un classificateur retournant tout le temps 0 aura une *accuracy* de 99%.\n",
    "\n",
    "## *Resampling*  (ou *class rebalancing techniques*)\n",
    "Quand collecter plus de données n'est pas possible, une solution peut être de rééquilibrer le *dataset* par rééchantillonnage en veillant à ne pas modifier la distribution à l'intérieur de chaque classe (ce que tous les algorithmes ne garantissent pas). On peut à cette fin utiliser des méthodes de sous-échantillonnage de la classe majoritaire (*under-sampling*), de sur-échantillonnage de la classe minoritaire (*over-sampling*), ou les deux en combinaison.\n",
    "\n",
    "On a pas à se limiter à un rééchantillonnage aléatoire qui finalement est assez pauvre et limitant. Il existe en effet tout un ensemble de techniques qui permettent 1) de rééquilibrer le dataset 2) d'améliorer sa séparabilité.\n",
    "\n",
    "### Avertissement sur les *class rebalancing techniques*\n",
    "Quelques remarques préliminaires importantes au sujet des *class rebalancing techniques*: \n",
    "* Comme toute opération consistant à transformer le *dataset*, celle-ci doit se faire **après** avoir séparé les données en *train* et *test set* **sous peine de *leakage***.\n",
    "* Les *class rebalancing techniques* (notamment celles visant à augmenter le *dataset*, i.e. l'*over-sampling*) présentent un risque de modifier la distribution du *training set*. Le *dataset* rééquilibré peut ne plus être représentatif du *dataset* original et dans ce cas défavorable, les concepts appris par le modèle peuvent s'en retrouver différents/biaisés (*concept drift*). On se retrouve également avec un écart entre notre *training set* et *test set* (ce dernier étant représentatif des donnés **avant** rééquilibrage) rendant délicat l'interprétation des métriques de performance du modèle. Par exemple, on fait souvent l'hypothèse qu'un *downsampling* de la classe majoritaire a un impact limité, notamment du point de vue de la modification de la distribution de celle-ci. Toutefois préserver la distribution n'est pas tout. Les SVM par exemple n'ont finalement besoin que des points \"frontaliers\" de chaque classe qu'ils utiliseront comme vecteurs de support. Un *downsampling* qui viendrait ainsi supprimer trop de ces points limites peut avoir un impact significatif sur la fonction finalement apprise et les performances du modèle.\n",
    "* En validation, veiller à ce qu'il n'y ait pas d'écart de représentativité entre chaque *fold* pour une bonne interprétabilité et stabilité des résultats (cf. `sklearn.model_selection.StratifiedKFold`).\n",
    "* La présence de données catégorielles impose l'utilisation de méthodes spécifiques (ou au moins en interdit certaines).\n",
    "\n",
    "### *Under-sampling* (ou *down-sampling*)\n",
    "La solution la plus simple reste le *random under-sampling* de la classe majoritaire qui rééquilibre le *dataset* sans modifier la distribution de la classe échantillonnée mais au prix d'une perte importante de données qu'on ne peut pas toujours se permettre. Afin de ne pas avoir à renoncer à utiliser une part potentiellement très importantes des données, la libraire `imblearn` (cf. plus bas) propose une utilisation intelligente des *ensemble methods* (*random forest*, *boosting*) dans laquelle chaque *weak learner* est entrainé sur un *dataset* sous-échantillonné aléatoirement différent. Toutes les observations de la classe majoritaire sont ainsi potentiellement utilisées.\n",
    "\n",
    "Remarque: Il existe en plus de la méthode aléatoire (`RandomUnderSampler`) toute une variété de méthode permettant de *down-sample* le *dataset*. Cf. `imblearn.under_sampling`. On peut citer notamment:\n",
    "* `imblearn.under_sampling.ClusterCentroids` qui *down-sample* la classe majoritaire en s'aidant d'un $k$-means: un ensemble de points de la classe majoritaire est remplacé par son barycentre. Noter que les représentants de la classe majoritaire après *down-sampling* sont générés et non sélectionnés.\n",
    "* `imblearn.under_sampling.NearMiss` qui regroupe différentes stratégies de sélection de membres de la classe majoritaire basée sur des notions de distance moyenne (à chaque stratégie correspond une définition de distance) à la classe majoritaire.\n",
    "\n",
    "### *Over-sampling*\n",
    "L'*over-sampling* consiste à rééquilibrer (à \"augmenter\") le *dataset* en augmentant la population de la classe majoritaire. Une première approche naïve consiste à rééchantillonner avec remise la classe majoritaire (cf. `imblearn.over_sampling.RandomOverSampler`). Cette approche est cependant peu efficace (mais a l'avantage de pouvoir s'appliquer quel que soit le type de données). Les algorithmes d'*over-sampling* vont consister à \"créer\" de nouvelles observations \"synthétiques\". Les principaux (d'ailleurs implémentés dans `imblearn`) sont le [SMOTE](https://arxiv.org/pdf/1106.1813.pdf) (*Synthetic Minority Oversampling TEchnique*) de Chawla et al. (2002) et [ADASYN](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/2008-He-ieee.pdf) (*Adaptive Synthetic*) de He et al. (2008).\n",
    "\n",
    "#### SMOTE\n",
    "SMOTE et ADASYN reposent globalement tous les deux sur le même algorithme:\n",
    "* Pour chaque membre de la classe minoritaire $x_{i}$ on va créer un nombre de nouveaux échantillons $g_i$ avec $\\sum_{i}g_i$ correspondant au nombre d'échantillons synthétiques nécessaires à l'atteinte de l'objectif pour arriver au ratio minoritaire/majoritaire demandé. On va alors un nombre $g_i$ de fois:\n",
    "    * Récupérer les membres $x_{i,r}$ de la même classe parmi ses $k$ plus proches voisins,\n",
    "    * Sélectionner aléatoirement un $x_{i,r}$,\n",
    "    * Générer un nouvel échantillon en le prenant sur le segment reliant $x_{i}$ à $x_{i,r}$ : $x_{new}=x_{i}+\\lambda (x_{i,r} - x_{i})$ avec $\\lambda$ un nombre aléatoire pris dans $[0, 1]$.\n",
    "\n",
    "SMOTE est cependant de nature à créer des artefacts assez gênants qui peuvent considérablement modifier la distribution de la classe minoritaires si celle-ci présente des *outliers* où n'est pas convexe par exemple. Dans le cas où la classe minoritaire présente des *outliers* par exemple, si pour un $x_i$ donné un *outlier* figure parmi les plus proches voisins et est sélectionné pour la génération d'échantillons, on peut se retrouver avec une trainée de nouvelles observations jusqu'à assez loin en dehors de la distribution \"normale\" de la classe minoritaire, voire recoupant la distribution d'une autre classe.\n",
    "\n",
    "#### *Borderline* SMOTE\n",
    "Une amélioration connue du SMOTE est le [*borderline* SMOTE](https://sci2s.ugr.es/keel/keel-dataset/pdfs/2005-Han-LNCS.pdf) de Han et al. (2005) qui établit une distinction entre les représentants de la classe minoritaires: \n",
    "* Si les $k$ plus proches voisins de $x_i$ sont tous de la classe majoritaire, alors il est considéré comme du bruit (NOISE) et ne pourra servir à la génération d'échantillons. \n",
    "* Si la majorité des $k$ plus proches voisins de $x_i$ sont de la classe minoritaire, alors il est considéré comme SAFE et ne sera pas non plus utilisé pour la génération d'échantillons. \n",
    "* Dernier cas, si la majorité mais pas la totalité des $k$ plus proches voisins de $x_i$ sont de la classe majoritaire, alors il est considéré comme \"dangereux\" (DANGER). Seuls les points classés DANGER seront utilisés pour la génération d'échantillons dans le SMOTE *borderline*.\n",
    "\n",
    "Cette version de l'algorithme est nommée *bordeline-1*, il existe une légère variante appelée *borderline-2* où les éléments de la classe majoritaire parmi les $k$ plus proches voisins sont sélectionnables pour la génération d'échantillons avec $\\lambda$ seulement pris dans $[0, 0.5]$, les échantillons générés l'étant alors plus \"près\" de la classe majoritaire. \n",
    "\n",
    "Le *borderline* SMOTE ne va par construction renforcer la densité de la distribution de la classe minoritaire qu'au niveau de ses marges (en atténuant les écueils du SMOTE \"standard\") ce qui peut suivant la méthode de classification choisie avoir un impact en termes de *concept drift*. On peut par exemple imaginer qu'un classificateur à marge type SVM sera moins impacté qu'un autre algorithme.\n",
    "\n",
    "Il existe de nombreuses autres variantes du SMOTE, voir notamment `imblearn.over_sampling`. \n",
    "\n",
    "#### ADASYN\n",
    "ADASYN est une variante du SMOTE \"standard\", où le nombre $g_i$ d'échantillons générés à l'aide des voisins de $x_i$ est proportionnel à la part de membres de la classe majoritaire dans les $k$ plus proches voisins de $x_i$. L'idée rapproche ADASYN du SMOTE *borderline* qui dans les deux cas visent en priorité les membres \"difficiles à apprendre\" de la classe minoritaire (par opposition aux membres dont les plus proches voisins sont tous de la classe minoritaire qui seront à priori plus faciles à discriminer).  \n",
    "\n",
    "Remarques: \n",
    "* Surveiller le ratio observations \"synthétiques\" sur observations originales. \n",
    "* Ces méthodes souffrent potentiellement des mêmes limitations que les méthodes \"plus proches voisins\" (*curse of dimensionality*, choix de la distance, etc.).\n",
    "\n",
    "## Adaptation des métriques utilisées\n",
    "Comme illustré plus haut, l'utilisation de l'*accuracy* n'est pas recommandée sauf si on est proche d'un équilibre entre les classes. On lui préfèrera la *balanced accuracy* définie comme la moyenne des *recalls* obtenus sur chaque classe et dont on comprend qu'elle a plus de sens dans le cas d'un *dataset* déséquilibré.\n",
    "\n",
    "Par construction, la courbe ROC n'est pas sensible à un déséquilibre éventuel entre classes et on recommande alors de préférer l'utilisation de la courbe *Precision-Recall* (PR) qui par l'utilisation de la *precision* devient sensible à un éventuel déséquilibre. Un classificateur peut en effet avoir une performance (AUC) honorable du point de vue de la courbe ROC mais catastrophique du point de vue de la courbe PR. Cf. notes sur les métriques.\n",
    "\n",
    "## Adaptation des algorithmes utilisés\n",
    "La plupart des algorithmes ne supportent pas le cas déséquilibré par défaut et l'oublier risque de conduire à des classificateurs fortement biaisés en faveur de la classe majoritaire:\n",
    "* Les algorithmes minimisant explicitement une fonction de coût pénalisent (ex: régression logistique) par défaut de la même manière une erreur faite sur la classe majoritaire et une erreur faite sur la classe minoritaire. Introduire une pondération (en général l'argument `class_weight` dans `sklearn`) permet de corriger le biais.\n",
    "* Dans le cas des CART (arbres de décision), les critères de *split* usuels font par défaut l'hypothèse d'une répartition équilibrée des classes.\n",
    "* Dans le cas d'autres algorithmes l'adaptation au déséquilibre (qui finit toujours par prendre la forme d'une pondération) peut être relativement spécifique (ex: SVM). \n",
    "\n",
    "## Autres options\n",
    "### Reformulation du problème: Détection d'anomalies\n",
    "Si le *dataset* est très déséquilibré et qu'il semble difficile d'établir une structure pour la classe minoritaire. Une possibilité est de changer d'approche (finalement à la suite d'une **mauvaise qualification du problème de départ**) et de voir le problème comme de la détection d'*outliers*. `sklearn` propose à cette date quatre algorithmes dédiés à cette catégorie de problèmes:\n",
    "* `sklearn.svm.OneClassSVM`\n",
    "* `sklearn.ensemble.IsolationForest`\n",
    "* `sklearn.neighbors.LocalOutlierFactor`\n",
    "* `sklearn.covariance.EllipticEnvelope`\n",
    "\n",
    "`sklearn` établit une distinction entre *outlier detection* et *novelty detection*. Pris au sens strict la première approche se contente de détecter les anomalies dans un *dataset* donné là où la seconde vise à apprendre une frontière de décision permettant ensuite d'assigner une nouvelle observation à la classe des *inliers* ou des *outliers* (le point jusqu'alors inconnu classé comme *outlier* est désigné comme *novelty*). Les méthodes de la seconde catégorie appartiennent également à la première catégorie. Cette distinction de comportement ne concerne finalement ici que `sklearn.neighbors.LocalOutlierFactor` qui est la seule méthode à ne pas véritablement apprendre de frontière de décision mais qui se contente de calculer un score (elle ne calcule que la déviation de densité locale d'un point par rapport à la densité locale moyenne de ses $k$ plus proches voisins). La méthode peut toutefois être utilisée en *novelty detection* moyennant l'activation d'une option.\n",
    "\n",
    "Remarque: Les methode d'*outlier detection* peuvent être utilisées pour nettoyer/débruiter un *dataset*.\n",
    "\n",
    "### Reformulation du problème: *Clustering*\n",
    "Si voir le problème comme un problème de *clustering* fonctionne (se pose ensuite le problème de rattacher une observation à un cluster lors de la prédiction), l'approche supervisée doit sans doute pouvoir fonctionner. A voir si cela est particulièrement adapté au besoin. Attention, il est possible que certaines méthodes de *clustering* souffrent (entre autres choses) de possibles déséquilibres entre les tailles des clusters à découvrir.\n",
    "\n",
    "Exemple: Utiliser des *gaussian mixtures* pour apprendre les distributions de chacune des deux classes plutôt que de chercher une frontière de décision.\n",
    "\n",
    "### Diminution du nombre de classes\n",
    "Comme pour les variables catégorielles présentant un trop grand nombre de niveaux à faibles population, on peut tirer partie de rassembler les membres de plusieurs (petites) classes au sein d'une même classe ou d'une classe plus peuplée.\n",
    "\n",
    "## Package `imblearn`\n",
    "[`imblearn`](https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html) ou `imbalanced-learn` est un [projet compatible](https://github.com/scikit-learn-contrib/imbalanced-learn) avec `sklearn` regroupant des utilitaires permettant d'effectuer des opérations de *resampling* de jeux de données déséquilibrés.  \n",
    "\n",
    "Les modèles de `imblearn` sont des `Estimator` présentant sur le modèle des `Estimator` de `sklearn` deux méthodes `fit` et `sample` et une méthode permettant de faire les deux à la fois `fit_resample`.\n",
    "\n",
    "```python\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "clf = LinearSVC()\n",
    "\n",
    "X_res, y_res = sample.fit_resample(X, y)\n",
    "clf.fit(X_res, y_res)\n",
    "```\n",
    "\n",
    "`imblearn` propose un analogue à l'objet `sklearn.Pipeline.pipeline`:\n",
    "\n",
    "```python\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "sampler = SMOTE(random_state=42)\n",
    "clf = LinearSVC()\n",
    "pipeline = make_pipeline(pca, sampler, clf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# fit_transform classique\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pipeline.predict(X_test)\n",
    "\n",
    "# Grid search\n",
    "param_range = range(1, 11)\n",
    "train_scores, validation_scores = validation_curve(pipeline, X_train, y_train, \n",
    "                                                   param_name=\"sampler__k_neighbors\", \n",
    "                                                   param_range=param_range,\n",
    "                                                   cv=3, scoring=\"precision\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
