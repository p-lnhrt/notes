{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calcul matriciel \n",
    "\n",
    "## Exemple introductif \n",
    "\n",
    "Soit $f$ une fonction de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$. La dérivée première de $f$ comportera $n$ éléments: on dérive la sortie qui est un scalaire par rapport à chacune des $n$ composantes de l'entrée. Le vecteur obtenu est appelé gradient de $f$ au point $x$ noté $\\nabla f(x)$. Il existe deux conventions pour se représenter les dérivées de fonctions vectorielles: \n",
    "* Le *numerator layout*: c'est la dimension du numérateur/de l'espace de d'arrivée (ce qu'on dérive) qui donne le nombre de ligne de la dérivée. Dans l'exemple ci-dessus, cela signifie que le gradient est vu comme un vecteur ligne de $\\mathcal{M}_{1,n}(\\mathbb{R})$. \n",
    "* Le *denominator layout*: c'est la dimension du dénominateur/de l'espace de départ (ce par rapport à quoi on dérive) qui donne le nombre de lignes. Dans l'exemple ci-dessus, cela signifie que le gradient est vu comme un vecteur colonne de $\\mathcal{M}_{n,1}(\\mathbb{R})=\\mathbb{R}^{n}$.\n",
    "\n",
    "Le passage d'une convention à l'autre se fait simplement en transposant. **On adopte ici la convention *numerator layout***.\n",
    "\n",
    "## Gradient, jacobienne, hessienne\n",
    "Dans le cas général d'une fonction de $f$ fonction de $\\mathbb{R}^{n}$ dans $\\mathbb{R}^{m}$, la dérivée première de $f$ au point $x$ est une matrice (chacune des $m$ composantes de la sortie doit être dérivée par rapport à chacune des $n$ composantes de l'entrée) appelée jacobienne de $f$ notée $J_{f}(x)$. \n",
    "\n",
    "Remarque : \n",
    "* En *numerator layout*, la jacobienne de $f$ sera une matrice de $\\mathcal{M}_{m,n}(\\mathbb{R})$\n",
    "* En *denominator layout*, la jacobienne de $f$ sera une matrice de $\\mathcal{M}_{n,m}(\\mathbb{R})$\n",
    "\n",
    "Dans le contexte de l'optimisation de fonctions de coût, les fonctions auxquelles on s'intéresse sont par construction de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$. On se situe alors dans le cas particulier où la dérivée première/jacobienne d'une fonction $f$ en un point $x$ n'a qu'une ligne (en convention *numerator layout*) et est donc représentable comme un simple vecteur appelé gradient de $f$ au point $x$ noté $\\nabla f(x)$. \n",
    "\n",
    "La \"dérivée seconde\" de $f$ de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ au point $x$ est en revanche une matrice carrée (chacune des $n$ composantes du gradient est une fonction de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ et peut donc être dérivée par rapport à chacune des $n$ dimensions de l'espace de départ) appelée hessienne de $f$ et notée $H_{f}(x)$. Si $f$ de $\\mathbb{R}^{n}$ dans $\\mathbb{R}^{m}$, la hessienne comme matrice n'a pas de sens, sauf à la considérer composante par composante ce qui revient à se ramener à des fonctions de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$.\n",
    "\n",
    "Remarque : Si $f$ de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ est suffisamment régulière (au moins $\\mathcal{C}^{2}$), sa hessienne est symétrique (conséquence immédiate du théorème de Schwarz).\n",
    "\n",
    "## Formulaire \n",
    "La construction d'un formulaire serait un peu lourde compte tenu de la combinatoire possible (fonction scalaire ou vectorielle / dérivée par rapport à un scalaire ou un vecteur, sans parler de fonctions de matricielles et de la dérivation par rapport à des matrices). Les cas simples (dérivée de la fonction multipliée par une constante, dérivée d'une constante, dérivée de la fonction identité) se retrouvent assez simplement par le calcul. Les cas plus compliqués demandent de développer le calcul, développement à l'issu duquel on peut reconnaitre l'expression matricielle correspondant à une identité remarquable pour ce type de calcul. Ces calculs peuvent devenir rapidement assez lourds et source d'erreurs, mais globalement: \n",
    "* S'en tenir à la même convention qui permet déjà de connaitre la dimension du résultat. \n",
    "* Dédramatiser : \n",
    "    * Pour une fonction vectorielle dérivée par rapport à un scalaire: on dérive chaque composante de la fonction par rapport à la variable scalaire, le résultat est donc un vecteur.\n",
    "    * Pour une fonction vectorielle dérivée par rapport à un vecteur: on dérive chaque composante de la fonction par rapport à chacune des composantes du vecteur par rapport auquel on dérive, le résultat est donc une matrice.\n",
    "    * Pour une fonction scalaire dérivée par rapport à un vecteur : on dérive la fonction par rapport à chacune des composantes du vecteur par rapport auquel on dérive, le résultat est donc un vecteur. Si on avait dérivé par rapport à une matrice, on aurait simplement dérivé par rapport à chacune composante de la matrice et le résultat aurait été une matrice.\n",
    "    * Il suffit ensuite de développer son calcul en prenant son temps.\n",
    "    \n",
    "On peut trouver [ici](https://en.wikipedia.org/wiki/Matrix_calculus#Derivatives_with_vectors) un certain nombre d'identités remarquables correspondant aux différents cas listés ci-dessus.\n",
    "\n",
    "Un exemple de cas d'usage du calcul matriciel en *machine learning*: Dans le cas de la régression linéaire, le problème de la recherche des coefficients correspond à un problème de minimisation d'un écart au sens des moindres carrés. Une approche possible pour ce problème consiste à le voir comme la minimisation par rapport au vecteur de paramètres $x$ de la fonction $x \\mapsto \\|Ax-b\\|^2=(Ax-b)^{\\top}.(Ax-b)$. Peut donc s'en suivre le calcul de la dérivée de cette fonction (scalaire) par rapport à $x$ (vecteur) et la résolution de l'équation (matricielle) obtenue en égalisant cette dérivée à zéro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimisation sous contraintes\n",
    "Remarque : le problème est souvent posé comme une minimisation d'une fonctionnelle $f$. Les résultats sont inchangés pour les problèmes de maximisation qui reviennent à minimiser $-f$. L'impact sur les éventuelles contraintes étant nul, ces dernières ne servant qu'à définir le domaine des valeurs admissibles.\n",
    "\n",
    "## Cas non contraint \n",
    "Pour $f$ d'un ouvert de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ différenciable (au moins $\\mathcal{C}^{1}$): \n",
    "\n",
    "**Une condition nécessaire (dite du premier ordre)** pour que $x^{*} \\in \\mathbb{R}^{n}$ soit un point critique de $f$ est que le gradient de $f$ s'annule en $x^{*}$ : $\\nabla f(x^{*})=0$.\n",
    "\n",
    "Rappel - Condition nécessaire : Du développement de la condition $\\nabla f(x^{*})=0$ on obtient un certain nombre de candidats $x^{*}$ qui ne sont pas tous des extrémums de $f$ mais parmi lesquels se trouvent tous les extrémums de $f$ s'ils existent.\n",
    "\n",
    "On peut ajouter à cette condition nécessaire, une **condition suffisante** pour que se réalise en $x^{*}$ un extrémum de $f$ : si $f$ suffisamment régulière (au moins deux fois différentiable) pour admettre une hessienne, alors :\n",
    "* $f(x^{*})$ est un minimum (local) pour $f$ si et seulement si $\\nabla f(x^{*})=0$ et $H_{f}$ la hessienne de $f$ symétrique (du fait de la régularité de $f$) définie positive.\n",
    "* $f(x^{*})$ est un maximum (local) pour $f$ si et seulement si $\\nabla f(x^{*})=0$ et $H_{f}$ la hessienne de $f$ symétrique (du fait de la régularité de $f$) définie négative.\n",
    "\n",
    "### Quel raisonnement qualitatif derrière cette condition du second ordre ?\n",
    "Comme pour les fonctions de $\\mathbb{R}$ dans $\\mathbb{R}$, il suffit d'écrire un développement de Taylor d'ordre 2 de $f$ au voisinage de $x^{*}$: Soit $h \\in \\mathbb{R}^{n}$ un vecteur situé au voisinage de $x^{*}$ et $f$ de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ supposée suffisamment régulière, alors (en convention numérateur): \n",
    "\n",
    "$$f(x^{*} + h) = f(x^{*}) + \\nabla f(x^{*}).h + \\frac{1}{2}h^{\\top}.H_{f}(x^{*}).h +\\|h\\|^{2} \\varepsilon(h)$$\n",
    "\n",
    "Avec $\\varepsilon(h) \\rightarrow 0$ lorsque $h \\rightarrow 0$\n",
    "\n",
    "Si $x^{*}$ point critique, alors le terme du premier ordre de l'équation ci-dessus est nul. On en déduit que $f(x^{*} + h) - f(x^{*})$ du même signe que $h^{\\top}.H_{f}(x^{*}).h$ d'où la relation entre la définitivité de $H_{f}$ et l'existence d'un extremum local.\n",
    "\n",
    "Ces conditions sur la hessienne correspondent au cas où $f$ adopte localement la forme d'un \"bol\" dans $\\mathbb{R}^{n}$. Elles sont finalement assez restricitives : plus la dimension est grande plus il est probable que la totalité des composantes de la hessienne ne soient pas du même signe. Les dimensions associées feront que ce point critique sera un point selle et donc un extremum instable : on peut a priori en sortir suivant ces directions là.\n",
    "\n",
    "#### Plan tangent\n",
    "Pour $f$ de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$, un plan tangent à $f$ en un point $x^{*}$ sera un hyperplan affine de $\\mathbb{R}^{n+1}$ (et donc par définition un espace de dimension $n$). Pour rappel, un hyperplan se définit comme le lieu des point orthogonaux à un vecteur normal au plan. \n",
    "\n",
    "Le plan tangent à $f$ en un point $x^{*}$ se définiera donc comme l'hyperplan passant par $(x^{*}, f(x^{*}))$ et de normale $\\nabla f(x^{*})^{\\top}$. Avec la définition d'un hyperplan affine, on peut donner une équation du plan tangent à $f$ en $x^{*}$: $h \\in \\mathbb{R}^{n}$ appartient au plan tangent à $f$ en $x^{*}$ s'il vérifie $f(x^{*}) + \\nabla f(x^{*}).h = 0$. \n",
    "\n",
    "Remarque: Cette égalité ne donne pas directement l'équation permettant de de tracer une représentation graphique du plan tangent dans $\\mathbb{R}^{n+1}$. Celle-ci s'obtient en trouvant une base du plan tangent (en s'appuyant notamment sur un vecteur normal vérifiant l'égalité ci-dessus) et en utilisant le fait que ce dernier passe par $(x^{*}, f(x^{*}))$.\n",
    "\n",
    "On reconnait les deux premiers termes du développement de Taylor au voisinage de $x^{*}$, $f$ peut ainsi s'approximer en $x^{*}$ comme la somme d'un vecteur appartenant à son plan tangent et de termes d'ordres supérieurs. On peut alors fournir une interprétation géométrique aux cas où la hessienne de $f$ en $x^{*}$ est définie positive ou négative. Développant à l'ordre 2, on constate facilement que $f(x^{*} + h) - (f(x^{*}) + \\nabla f(x^{*}).h)$ est du même signe que $h^{\\top}.H_{f}(x^{*}).h$ ($h$ ici quelconque et donc pas forcément une normale au plan tangent). On en déduit que:\n",
    "* Lorsque $H_{f}(x^{*})$ définie strictement positive, $f$ est toujours au-dessus de son plan tangent au voisinage de $x^{*}$. \n",
    "* Lorsque $H_{f}(x^{*})$ définie strictement négative, $f$ est toujours au-dessous de son plan tangent au voisinage de $x^{*}$. \n",
    "\n",
    "## Optimisation sous contraintes d'égalité : multiplicateurs de Lagrange\n",
    "La méthode des multiplicateurs de Lagrange est une technique d'optimisation visant à trouver une ou des solutions au problème d'optimisation d'une fonction différenciable $f$ d'un ouvert de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$ sous $m$ contraintes de la forme $g_{i}(x) = 0$ avec $g_{i}$ différentiables et à valeurs de $\\mathbb{R}^{n}$ dans $\\mathbb{R}$.\n",
    "\n",
    "Le principe de la méthode est de ramener la recherche d'extremums de $f$ sous contraintes à l'étude d'une fonction particulière $\\mathcal{L}$ appelée lagrangien à valeurs de $\\mathbb{R}^{n} \\times \\mathbb{R}^{m}$ dans $\\mathbb{R}$ et se définissant ainsi : \n",
    "\n",
    "$$\\mathcal{L}:(x,\\lambda) \\mapsto f(x)+\\lambda^{\\top}.g(x)$$\n",
    "\n",
    "Globalement, on montre que si $x^{*}$ est une solution du problème contraint, alors il existe un vecteur $\\lambda^{*} \\in \\mathbb{R}^{m}$ (appelé vecteur des multiplicateurs de Lagrange) tel que la différentielle de $\\mathcal{L}$ est nulle au point $(x^{*},\\lambda^{*})$ (les dérivées partielles de $\\mathcal{L}$ par rapport à $x$ et $\\lambda$ sont nulles en $(x^{*},\\lambda^{*})$). Dit autrement, si $x^{*}$ est un point critique faisable de $f$, alors il existe un vecteur $\\lambda^{*}$ tel que $(x^{*},\\lambda^{*})$ point critique de $\\mathcal{L}$.\n",
    "\n",
    "Cette méthode a le double avantage: \n",
    "* De nous ramener d'un problème d'optimisation sous contraintes (de $f$) à un problème d'optimisation non contraint (de $\\mathcal{L}$).\n",
    "* De simplifier la résolution du problème en évitant une paramétrisation par les contraintes. \n",
    "\n",
    "**Théorème des multiplicateurs de Lagrange** : Soit $x^{*} \\in \\mathbb{R}^{n}$ faisable ($g(x^{*})=0$), régulier (les gradients des contraintes en $x^{*}$ sont linéairement indépendants) et point critique de $f$, alors $\\exists !\\lambda^{*} \\in \\mathbb{R}^{m}$ tel que le gradient du lagrangien $\\mathcal{L}$ au point $(x^{*}, \\lambda^{*})$ est nul : $\\nabla \\mathcal{L}({x}^{*}, {\\lambda}^{*})=0$ (tel que $(x^{*}, \\lambda^{*})$ soit un point critique pour $\\mathcal{L}$).\n",
    "\n",
    "Remarques: \n",
    "* En convention numérateur: $\\nabla f(x^{*}) \\in \\mathcal{M}_{1,n}(\\mathbb{R})$ et $\\nabla g(x^{*}) \\in \\mathcal{M}_{m,n}(\\mathbb{R})$\n",
    "* Le caractère régulier de $x^{*}$ assure de l'existence et de l'unicité du vecteur de multiplicateurs $\\lambda^{*}$. On trouve facilement des exemples où il existe (ou pas) un vecteur de multiplicateurs pour $x^{*}$ critique pour $f$ mais non régulier.\n",
    "\n",
    "Le théorème des multiplicateurs de Lagrange énonce donc une condition nécessaire du premier ordre pour le problème contraint. On remarque que cette condition implique la colinéarité des gradients de $f$ et des contraintes $g$ au point critique $(x^{*},\\lambda^{*})$ : $\\nabla_{{x}} \\mathcal{L}({x}^{*}, {\\lambda}^{*})=0 \\iff \\nabla f(x^{*}) + \\lambda^{*\\top}.\\nabla g(x^{*}) = 0$\n",
    "\n",
    "Les conditions nécessaires du premier ordre prennent ainsi la forme de deux égalités: \n",
    " * $\\nabla_{{x}} \\mathcal{L}({x}^{*}, {\\lambda}^{*})=0$ qui exprime la colinéarité des gradients au point critique.\n",
    " * $\\nabla_{\\lambda} \\mathcal{L}({x}^{*}, {\\lambda}^{*})=0$ qui exprime le respect des contraintes d'égalité. \n",
    "\n",
    "La résolution de problèmes d'optimisation consiste généralement à développer ces équations afin de voir si le système obtenu admet des solutions $(x^{*}, \\lambda^{*})$. D'après le théorème des multiplicateurs de Lagrange, les solutions $x^{*}$ obtenues sont des candidats (réguliers) à la résolution du problème d'optimisation. Le théorème ne constituant qu'un condition nécessaire, tous les points critiques de $\\mathcal{L}$ ne sont pas critiques pour $f$ mais l'inverse est vrai ; on est sûr que tous les points critiques de $f$ se trouvent dans les candidats obtenus.\n",
    "\n",
    "Remarque: Au delà du caractère seulement nécessaire de la condition donnée par le théorème des multplicateurs de Lagrange, les solutions obtenues si extrémales ne sont dans le cas général que des extrémums locaux (mais sont globaux dans certains problèmes comme les problèmes convexes pour lesquels la condition est aussi suffisante).\n",
    "\n",
    "### Quel raisonnement qualitatif derrière la condition de colinéarité des gradients ? \n",
    "On peut approcher le problème comme une descente de gradient classique: afin d'atteindre un minimum local (on a juste à adapter le raisonnement pour un maximum local), on va à chaque étape descendre $f$ dans la direction opposée à celle de son gradient $\\nabla_{x} f$ au point où on se trouve. On ajoute à cela la contrainte de decendre $f$ en restant en permanence sur la surface des contraintes $g$. Ainsi, un déplacement $\\delta x >0$ nous rapprochant d'une solution du problème contraint doit respecter deux égalités: \n",
    "* $\\delta x.(-\\nabla_{x}f(x)) > 0$ traduisant le fait qu'on veuille se déplacer dans la direction opposée à celle du gradient de $f$\n",
    "* $\\delta x.\\nabla_{x}g(x)) = 0$ traduisant le fait qu'on veuille se déplacer en se maintenant sur la surface des contraintes. $\\nabla_{x}g(x)$ est en effet la normale à la surface des contraintes au point $x$, et une condition nécessaire pour qu'un déplacement infinitésimal $\\delta x$ se fasse sans quitter cette surface est que ce déplacement soit orthogonal à la normale de la surface à son point de départ.\n",
    "\n",
    "A l'optimum, il n'est plus possible de faire diminuer la fonction de coût en restant sur la surface des contraintes. Les deux conditions précédentes deviennent alors $\\delta x.(-\\nabla_{x}f(x^{*})) = 0$ et $\\delta x.\\nabla_{x}g(x^{*})) = 0$ pour tout $\\delta x$ ce qui implique que $\\nabla_{x}f(x^{*})$ et $\\nabla_{x}g(x^{*})$ soient colinéaires.\n",
    "\n",
    "### Forme de la condition suffisante du second ordre\n",
    "Comme dans le cas non contraint, on peut donner pour ce problème des conditions du second ordre suffisantes pour la réalisation d'un extrémum. Dans le cas du problème avec contraintes d'égalité, aux conditions nécessaires du premier ordre données plus haut on peut ajouter suivant les cas, pour $x^{*}$ faisable, critique et régulier:\n",
    "* Une condition suffisante de réalisation d'un minimum local: $\\forall y \\in \\mathbb{R}^{n}$ tels que $y^{\\top}.\\nabla g(x^{*})=0, y^{\\top}.H_{\\mathcal{L}_{x}}(x^{*}, \\lambda^{*}).y \\ge 0$ (Hessienne de $\\mathcal{L}$ définie-positive en $(x^{*}, \\lambda^{*})$).\n",
    "* Une condition suffisante de réalisation d'un maximum local: $\\forall y \\in \\mathbb{R}^{n}$ tels que $y^{\\top}.\\nabla g(x^{*})=0, y^{\\top}.H_{\\mathcal{L}_{x}}(x^{*}, \\lambda^{*}).y \\le 0$ (Hessienne de $\\mathcal{L}$ définie-négative en $(x^{*}, \\lambda^{*})$).\n",
    "\n",
    "Où $H_{\\mathcal{L}_{x}}$ est la hessienne du lagrangien calculée par rapport à $x$. Ces conditions expriment mathématiquement l'idée suivante: \n",
    "* Dans le cas du minimum, pour tout vecteur $y$ du plan tangent à la surface des contraintes en $x^{*}$, la hessienne du lagrangien en $x^{*}$ doit être définie positive, ce qui est équivalent à montrer que pour tout voisinage local de $x^{*}$ sur la surface des contraintes (condition sur $y$), le lagrangien prend dans ce voisinage admissible une valeur toujours supérieure ou égale à celle prise en $x^{*}$ d'où la réalisation d'un minimum local.\n",
    "* Idem pour le maximum mais dans l'autre sens.\n",
    "\n",
    "### Interprétation des multiplicateurs de Lagrange\n",
    "Prenons le multiplicateur $\\lambda_{i}^{*}$ associé à la contrainte $g_{i}$. Une rapide analyse dimensionnelle s'appuyant sur la condition de colinéarité des gradients montre que $\\lambda_{i}^{*}$ a pour unité \"unité de $f$/unité de $g_{i}$\". D'où les interprétations des multiplicateurs liées à une analyse de sensibilité de la fonction objectif aux contraintes: une variation $\\delta g_{i}$ de la contrainte se traduit par une variation $\\lambda_{i}^{*}.\\delta f$ de la fonction objectif. \n",
    "\n",
    "Dans le cas où les fonctions objectifs s'exprimes en unités monétaires, les multplicateurs peuvent par exemple s'interpréter comme le prix qu'on serait prêt à payer pour relacher la contrainte et obtenir un incrémemnt correspondant de la fonction objectif (*shadow price)*.\n",
    "\n",
    "Reposant sur une approximation linéaire de $f$, ces raisonnements ne sont évidemment valables qu'au voisinage de l'optimum.\n",
    "\n",
    "## Optimisation sous contraintes d'égalité et/ou d'inégalité: Théorème de Karush-Kuhn-Tucker\n",
    "Aux $m$ contraintes d'égalité $g_{i}(x)=0$ s'ajoutent désormais $p$ contraintes d'inégalité qu'on ramène toutes à la forme normalisée $h_{i}(x) \\le 0$. Le domaine de faisabilité de $x$ ne correspond plus à une surface de contraintes dans $\\mathbb{R}^{n}$ mais à un volume de $\\mathbb{R}^{n}$, l'optimum pouvant se trouver à l'intérieur de celui-ci. On distingue alors deux situations pour un $x^{*}$ donné : \n",
    "* Cas des contraintes insaturées : tout se passe comme si ces contraintes n'impactaient pas le problème et la recherche d'un point critique se ramène au cas non contraint.\n",
    "* Cas des contraintes saturées : elles nous ramènent par définition à la recherche d'un optimum sous contraintes d'égalité.\n",
    "\n",
    "L'étude de ce problème contraint s'appuie de nouveau sur l'utilisation d'un lagrangien $\\mathcal{L}$ à valeurs de $\\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\times \\mathbb{R}^{p}$ dans $\\mathbb{R}$: \n",
    "\n",
    "$$\\mathcal{L}:(x,\\lambda, \\mu) \\mapsto f(x)+\\lambda^{\\top}.g(x)+\\mu^{\\top}.h(x)$$\n",
    "\n",
    "De manière analogue au théorème de Lagrange, on peut donner des conditions nécessaires du premier ordre pour le problème contraint.\n",
    "\n",
    "**Théorème des multiplicateurs de Karush-Kuhn-Tucker** : Soit $x^{*} \\in \\mathbb{R}^{n}$ faisable ($g(x^{*})=0$ et $h(x^{*})\\leq0$), régulier (les gradients des contraintes en $x^{*}$ sont linéairement indépendants) et point critique de $f$, alors $\\exists !(\\lambda^{*}, \\mu^{*}) \\in \\mathbb{R}^{m} \\times \\mathbb{R}^{p}$ tels qu'au point $(x^{*}, \\lambda^{*}, \\mu^{*})$ les conditions suivantes sont vérifiées: \n",
    "* Le gradient du lagrangien $\\mathcal{L}$ est nul : $\\nabla \\mathcal{L}({x}^{*}, {\\lambda}^{*}, \\mu^{*})=0$\n",
    "* $\\mu^{*} \\ge 0$\n",
    "* $\\mu^{*}_{j}.h_{j}(x^{*})=0$ \n",
    "\n",
    "Reformulées, les trois conditions ci-dessus donnent cinq conditions plus connues sous le nom de conditions de Karush-Kuhn-Tucker (KKT):\n",
    "* $\\nabla_{{x}} \\mathcal{L}({x}^{*}, {\\lambda}^{*}, {\\mu}^{*})=0$ : Traduit la colinéarité des gradients en $(x^{*}, \\lambda^{*}, \\mu^{*})$\n",
    "* $\\nabla_{\\lambda} \\mathcal{L}({x}^{*}, {\\lambda}^{*}, {\\mu}^{*})=0$ : Traduit le respect des contraintes d'égalité (primal).\n",
    "* $\\nabla_{\\mu} \\mathcal{L}({x}^{*}, {\\lambda}^{*}, {\\mu}^{*}) \\ge 0$ : Traduit le respect des contraintes d'inégalité (primal).\n",
    "* $\\mu^{*} \\ge 0$ : Traduit le respect des contraintes de faisabilité du problème dual (les hypothèses ci-dessus sous-entendent qu'on se trouve en situation de dualité forte, cf. partie suivante).\n",
    "* $\\mu^{*}_{j}.h_{j}(x^{*})=0$ (*complementary slackness*) : Traduit le fait que soit $x^{*}$ sature certaines contraintes d'inégalité et les $\\mu^{j}$ correspondants sont non nuls (on est alors ramené au cas de contraintes d'égalité), soit $x^{*}$ ne sature pas certaines contraintes d'inégalité et les $\\mu^{j}$ correspondants sont nuls (on est alors ramené au cas non contraint).\n",
    "\n",
    "La résolution de problèmes d'optimisation est similaire à celle utilisée dans le cas des multiplicateurs de Lagrange : on cherche des solution candidates au problème en développant les systèmes d'équations ci-dessus.\n",
    "\n",
    "Comme pour le cas avec égalités, les solutions retenues ne sont dans le cas général que des extrémums locaux qui sont également globaux pour les problèmes convexes.\n",
    "\n",
    "Il existe certaines classes de problèmes comme par exemple les problèmes convexes pour lesquels ces conditions sont également des conditions suffisantes d'optimalité. \n",
    "\n",
    "### Optimisation et dualité\n",
    "Soit le problème d'optimisation dit primal écrit sous sa forme standard en notant $p^{*}$ la valeur de la fonction objectif $f$ à l'optimum:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cl}{\\min_{x \\in \\mathbb{R}^{n}}} & {f(x)} \\\\ {\\text { subject to }} & {g_{i}(x) = 0, i=1, \\ldots, m} \\\\ {} & {h_{j}(x) \\leq 0, j=1, \\ldots, p}\\end{array}\n",
    "$$\n",
    "\n",
    "Le lagrangien associé à ce problème est la fonction $\\mathcal{L} : \\mathbb{R}^{n} \\times \\mathbb{R}^{m} \\times \\mathbb{R}^{p} \\rightarrow \\mathbb{R}$:\n",
    "\n",
    "\n",
    "$$\\mathcal{L}:(x,\\lambda, \\mu) \\mapsto f(x)+\\lambda^{\\top}.g(x)+\\mu^{\\top}.h(x)$$\n",
    "\n",
    "Où les vecteurs $\\lambda$ et $\\mu$ sont appelés vecteurs des multiplicateurs de Lagrange et correspondent également au variables du problème dual associé à ce problème (primal) d'optimisation (voir ci-après).\n",
    "\n",
    "On définit en effet la fonction duale de Lagrange $q : \\mathbb{R}^{m} \\times \\mathbb{R}^{p} \\rightarrow \\mathbb{R}$ : \n",
    "\n",
    "$$q(\\lambda, \\mu) = \\inf_{x} \\mathcal{L}(x, \\lambda, \\mu)$$\n",
    "\n",
    "La fonction duale possède deux propriétés très générales:\n",
    "* Elle est concave pour toute valeur de $\\lambda$ et $\\mu$ et cela sans faire d'hypothèses sur les fonctions $f$, $g_{i}$ et $h_{j}$\n",
    "* Pour tout point $x$ primal-faisable et $\\mu_{i} \\geq 0$, $q$ constitue une borne inférieure pour $f$ : $q(\\lambda, \\mu) \\leq f(x)$. Là encore cette inégalité est très générale et ne nécessite aucune hypothèse sur les fonctions $f$, $g_{i}$ et $h_{j}$.\n",
    "\n",
    "Remarques:\n",
    "* Il peut être difficile voire impossible de calculer une forme explicite pour $q$.\n",
    "* Pour certaines valeurs de $\\lambda$ et $\\mu$, $q(\\lambda, \\mu) = \\inf_{x} \\mathcal{L}(x, \\lambda, \\mu)$ peut prendre la valeur de $-\\infty$.\n",
    "\n",
    "On définit le problème dual (et note $d^{*}$ la valeur atteinte par sa fonction objectif à l'optimum) associé au primal décrit plus haut par le problème d'optimisation : \n",
    "\n",
    "$$\n",
    "\\begin{array}{cl}{\\max_{\\lambda, \\mu}} & {q(\\lambda, \\mu)} \\\\ {\\text { subject to }} & {\\mu_{j} \\geq 0, j=1, \\ldots, p}\\end{array}\n",
    "$$\n",
    "\n",
    "Du fait des propriétés générales de $q$: \n",
    "* Le problème dual est toujours convexe même quand le primal ne l'est pas. Cette propriété explique en partie l'attractivité du problème dual qui peut s'avérer beaucoup plus simple à résoudre que le primal. Les problème dual présente également souvent beaucoup moins de contraintes et des contraintes de surcroît très simples.\n",
    "* De la propriété de borne inférieure on déduit facilement l'inégalité dite de dualité faible (*weak duality equality*) : $d^{*} \\leq p^{*}$.\n",
    "\n",
    "Remarque sur l'inégalité $q(\\lambda, \\mu) \\leq f(x)$:\n",
    "Cette inégalité est en fait très générale, on peut en effet montrer que le problème primal est équivalent au problème suivant:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cl}{\\min_{x \\in \\mathbb{R}^{n}}} & {\\sup_{\\mu \\geq 0} \\mathcal{L}(x, \\lambda, \\mu)} \\\\ {\\text { subject to }} & {g_{i}(x) = 0, i=1, \\ldots, m} \\\\ {} & {h_{j}(x) \\leq 0, j=1, \\ldots, p}\\end{array}\n",
    "$$\n",
    "\n",
    "En effet, sous la condition $\\mu \\geq 0$, le suprémum du lagrangien est égal à $f(x)$, ce suprémum ne prenant de valeur finies que pour les points primal-faisables ($+\\infty$ sinon). Or n'importe quelle fonction $f$ vérifie l'inégalité suivante: \n",
    "\n",
    "$$\\sup _{z \\in Z} \\inf _{w \\in W} f(w, z) \\leq \\inf _{w \\in W} \\sup _{z \\in Z} f(w, z)$$\n",
    "\n",
    "De cette inégalité et des définitions des problèmes dual et primal, on en déduit immédiatement l'inégalité de dualité faible et son caractère très général.\n",
    "\n",
    "Le cas d'égalité de l'inégalité de dualité faible ($d^{*} = p^{*}$) est appelé situation de dualité forte (*strong duality*). C'est un cas intéressant et recherché car entre autres choses, la résolution du dual nous donne la valeur de la fonction objectif du primal à l'optimum. Si l'inégalité de dualité faible est toujours valable, l'égalité de dualité forte n'est pas vérifiée par tous les problèmes. Pour s'assurer de l'égalité, il faut poser des conditions supplémentaires sur les contraintes $g_{i}$ et $h_{j}$ qu'on appelle conditions de qualification des contraintes (*contraint qualification*).\n",
    "\n",
    "Il existe de nombreuses conditions de qualification. Une des plus connues est la condition de Slater qui s'énonce pour le problème suivant :\n",
    "\n",
    "$$\n",
    "\\begin{array}{cl}{\\min_{x \\in \\mathbb{R}^{n}}} & {f(x)} \\\\ {\\text { subject to }} & {h_{j}(x) \\leq 0, i=p, \\ldots, m, h_{i} convexe} \\\\ {} & {Ax=b}\\end{array}\n",
    "$$\n",
    "\n",
    "La condition de Slater impose donc que le problème soit convexe: les contraintes d'inégalité sont des fonctions convexes et les contraintes d'égalité des fonctions affines (définition qui inclut notamment les programmes linéaires). On peut la reformulter ainsi: Si pour un problème convexe, il existe au moins un point $x$ (primal) faisable qui ne sature pas les contraintes d'inégalité (toutes les inégalités sont strictes), alors le maximum de la fonction duale est atteint ($\\exists \\lambda^{*}, \\mu^{*}$ tels que $q(\\lambda^{*}, \\mu^{*})=d^{*}$) et l'égalité de dualité forte est valide ($d^{*} = p^{*}$). La condition de Slater donne ainsi une condition suffisante de dualité forte pour les problèmes convexes.\n",
    "\n",
    "Supposons **$x^{*}$ primal-optimal, $(\\lambda^{*}, \\mu^{*})$ dual-optimal et l'égalité de dualité forte valable**, on montre alors sans plus d'hypothèses que : \n",
    "* $x^{*}$ minimise le lagrangien en $(\\lambda^{*}, \\mu^{*})$. Si on ajoute comme condition la différentiabilité de  $f$, $g_{i}$ et $h_{j}$, comme $x^{*}$ est alors extrémum du le lagrangien en $\\lambda^{*}$ et $\\mu^{*}$ (fixés), il en découle immédiatement : $\\nabla_{{x}} \\mathcal{L}({x}^{*}, {\\lambda}^{*}, {\\mu}^{*})=0$ (colinéarité des gradients). Dit autrement, étant donnée une solution $(\\lambda^{*}, \\mu^{*})$ du dual, toute solution optimale du primal $x^{*}$ satisfait nécéssairement la condition du premier ordre ci-dessus. Cette propriété est particulièrement utile si la résolution du dual est plus aisée que celle du primal: connaissant $(\\lambda^{*}, \\mu^{*})$ on va rechercher des candidats $x^{*}$ à l'aide de l'équation ci-dessus.\n",
    "* Pour tout $i$, on a : $\\mu_{j}^{*}.h_{j}(x^{*})=0$ : soit la contrainte (d'inégalité) est saturée, soit son multiplicateur de Lagrange associé est nul (*complementary slackness*). \n",
    "\n",
    "Si aux deux lots d'égalités obtenus ci-dessus, on ajoute les conditions de faisabilité du primal ($g_{i}(x^{*}) = 0$ et $h_{i}(x^{*}) \\leq 0$) et du dual ($\\mu^{*} \\geq 0$), on obtient ce qu'on appelle les conditions de Karush-Kuhn-Tucker (KKT).\n",
    "\n",
    "On obtient alors une condition nécéssaire : Si $x^{*}$ primal-optimal, $(\\lambda^{*}, \\mu^{*})$ dual-optimal et l'égalité de dualité forte valable (et $f$, $g_{i}$ et $h_{j}$ différentiables), alors les conditions KKT sont satisfaites. En situations de dualité forte, les KKT sont une condition nécessaire d'optimalité.\n",
    "\n",
    "On montre de plus que si le problème est convexe, alors les conditions KKT sont suffisantes.\n",
    "\n",
    "Dans le cas de problèmes satisfaisant des conditions de qualification des contraines (ex: les problèmes convexes et les conditions de Slater), la dualité forte est assurée et la formulation des conditions précédemment énoncées s'en retrouve simplifiée. Ainsi, pour un problème convexe, $x^{*}$ primal-optimal et $(\\lambda^{*}, \\mu^{*})$ dual-optimal si et seulement si les KKT sont satisfaites.\n",
    "\n",
    "Remarques : Lien entre les KKT de cette partie et le \"théorème KKT\" de la partie précédente \n",
    "* Dans formulation de la condition nécessaire donnée dans la partie précédente, le caractère régulier de $x^{*}$ semble être équivalent/remplacer l'existence de $(\\lambda^{*}, \\mu^{*})$ dual-optimal. \n",
    "* Le \"théorème KKT\" donné dans la partie précédente ne fait pas non plus mention de la situation de dualité forte. Il est probable que celle-ci est souvent sous-entendue et garantie par la forme des problèmes étudiés qui satisfont à une ou plusieurs conditions de qualification des contraintes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
