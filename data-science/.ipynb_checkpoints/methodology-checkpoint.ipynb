{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démarche\n",
    "## 1. Exploration préliminaire\n",
    "Consiste à produire un certains nombre de statistiques descriptives et de graphiques pour mieux comprendre ses données:\n",
    "* Types de variables: \n",
    "    * Continues: distribution, présence de valeurs abérrantes/d'*outliers*/d'échantillons indésirables (ne correspondant pas à la population qu'on souhaite étudier).\n",
    "    * Catégorielles: ordinales ou pas ? cardinalité, distribution des effectifs par classe.\n",
    "* Formulation du problème: régression, classification (*dataset* déséquilibré ? binaire ou multiclasse ?), non supervisé (détection d'anomalies, clustering, etc.).\n",
    "\n",
    "## 2. Nettoyage\n",
    "* Filtrage des échantillons indésirables, application de corrections (ex: erreurs de mesure) après validation du métier.\n",
    "* Débruitage complémentaire: suppression des *outliers* s'ils ne nous intéressent pas et vont au contraire perturber l'apprentissage du modèle (induire une variance élevée). Si on ne les supprime pas, il faut considérer leur présence (même éventuelle) lors du choix du modèle: Est-il particulièrement sensible aux *outliers* ? Quelles autres mesures pouvons nous prendre pour limiter leur impact sur la qualité de l'apprentissage (régularisation, choix d'une norme L1 pluôt que L2, standardisation robuste, etc.) ?\n",
    "\n",
    "## 3. Gestion des valeurs manquantes\n",
    "En cas de présence de valeur manquantes, choisir entre suppression et imputation puis si imputation, une stratégie adaptée au type de données:\n",
    "* Choisir la strégie limitant au maximum l'impact sur la distribution originale des données: risque de *concept drift*.\n",
    "* Les stratégies d'imputation utilisant l'information du reste du *dataset* pour imputer, attention au risque de de *leakage*.\n",
    "\n",
    "## 4. Encodage des variables catégorielles\n",
    "En cas de présence de variables catégorielle, choisir la stratégie d'encodage la plus adaptée en prenant garde au risque de *leakage* associée à certaines stratégies (*embeddings*, encoders bayésiens, etc.). \n",
    "\n",
    "## 5. Rééquilibrage du *dataset*\n",
    "En cas de problème de classification et de déséquilibre entre les classes, choisir la stratégie de rééquilibrage des effectifs des classes: \n",
    "* Choisir la strégie limitant au maximum l'impact sur la distribution originale des données: risque de *concept drift*.\n",
    "* Un bon nombre d'algorithmes de rééquilibrage peuvent présenter un risque de de *leakage* (Ex: tous les algorithmes à base de plus proches voisins).\n",
    "* Ne pas oublier: \n",
    "    * Les modèles présupposent par défaut que les *datasets* sont équilibrés. Lors du choix du modèle, activer le mode permettant de compenser ce déséquilibre si le rééquilibrage n'a fait que le réduire sans le faire disparaître.\n",
    "    * Certaines métriques de performance sont peu adaptées à l'évaluation de modèles entrainés sur des *datasets* déséquilibrés. Ex: *ROC curve* vs. *PR curve*.\n",
    "\n",
    "## 6. *Feature engineering* et transformation des *features* \n",
    "On inclut dans cette étape la création de *features* basée sur la compréhension du problème (*feature engineering*) et l'éventuelle transformation de celles-ci pour les conformer au format d'entrée attendu par le modèle (Ex: données centrées, centrées et réduites, suivant une distribution normale, données faiblement corrélées, etc.):\n",
    "* Quand la transformation implique une modification de la distribution des données: risque de *concept drift*\n",
    "* Certaines transformation (Ex: *scaling*) utilisent l'information de l'ensemble du *dataset*: attention au risque de de *leakage*.\n",
    "* Normaliser est en général un minimum notamment si les *features* s'expriment dans des unités très différentes au prix d'une perte d'information limitée (variances relatives). Attention à l'impact d'éventuels *outliers*.\n",
    "\n",
    "## 7. Réduction de la dimension / sélection de *features*\n",
    "Chercher à réduire le nombre de variables passées du modèle avant l'entrainement permet d'éviter les problèmes de *curse of dimensionality* mais aussi de se limiter aux variables a priori les plus pertinentes (on se restreint à une *sparse solution*) améliorant d'autant les performances de calcul et l'interprétabilité du modèle. Attention, certaines stratégies sont *greedy*. Certains modèles permettent d'inclure la sélection de *features* au modèle via la régularisation (Ex: LASSO), on parle alors d'*embedded feature selection*.\n",
    "\n",
    "La réduction de dimension peut se faire de manière non supervisée (ex: PCA) ou supervisée.\n",
    "\n",
    "## 8. Choix du modèle et d'une stratégie de régularisation \n",
    "Quand on choisit un modèle et une stratégie de régularisation, examiner la capacité de celui-ci à faire face aux problèmes classiques rencontrés en pratique:\n",
    "* Comportement en présence de *features* fortement corrélées.\n",
    "* Comportement en présence de bruit/de *features* non informatives.\n",
    "* Comportement en présence d'*outliers* (robustesse).\n",
    "* Capacité à gérer les valeurs manquantes, sinon: cf. stratégies de gestion des valeurs manquantes.\n",
    "* Capacité à gérer des données mixtes, sinon: cf. encodage des variables catégorielles. \n",
    "* Interprétabilité.\n",
    "* En cas de déséquilibre dans les données en classification, comment ce problème est-il géré ?\n",
    "* Comportement face à une dimensionnalité élevée (exemple des algorithmes se basant sur des distances).\n",
    "* *Scalability*: Complexité algorithmique (impactée par le nombre d'observations $n$ ET le nombre de *features* $p$) / possibilité de paralléliser l'entrainement.\n",
    "\n",
    "## 9. Stratégie de validation, sélection du modèle, *tuning* des hyperparamètres\n",
    "En fonction de la quantité de données disponible, déterminer:\n",
    "* Les proportions de données finissant dans *training*, *validation* et *test* set. Veiller à placer ce *split* avant toute étape susceptible d'introduire du *leakage*.\n",
    "* Les métriques à calculer lors de la validation afin de sélectionner le modèle. Ex: *ROC curve* vs. *PR curve* en cas de *dataset* déséquilibré. \n",
    "* Combien de *folds* doivent être utilisées pour la cross-validation sachant que si ce nombre est trop faible, on risque d'avoir une forte variance (à minima un large intervalle de confiance) pour les métriques de validations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
