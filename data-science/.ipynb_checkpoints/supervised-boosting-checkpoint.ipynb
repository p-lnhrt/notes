{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Boosting*\n",
    "Le *boosting* est comme le *bagging* une *ensemble method*, c'est à dire une méthode visant à construire un estimateur composite. Le *boosting* se repose sur 2 idées principales:\n",
    "* L'estimateur d'ensemble est spécifié comme une somme pondérée d'estimateurs faibles (*weak learners*) au sens de fortement biaisés: $f(x)=\\sum_{m=1}^{M} v_{m} h_{m}(x)$. L'estimateur global a une performance très supérieure aux estimateurs individuels le composant, leur performance se retrouvant ainsi \"boostée\" par le fait d'être combinés dans un ensemble. Tous les *weak learners* $h_m$ appartiennent à la même famille de modèles (espace de fonctions appelé *hypothesis space* $\\mathcal{H}$): CART, etc.\n",
    "* L'estimateur d'ensemble dont on a postulé une forme additive est construit selon une méthodologie particulière: le *forward stagewise additive modeling* (FSAM). Il s'agit d'une méthode séquentielle dont chaque étape consiste en l'ajout d'une nouvelle fonction de base, les paramètres de tous les autres modèles déjà ajoutés restant fixés lors du *fit* de cette dernière. Le modèle initial étant très fortement biaisé, l'idée est que chaque étape va venir en diminuer le biais.\n",
    "\n",
    "Remarques : \n",
    "* On trouve parfois $v_{m}=1$ qui fait implictement l'hypothèse que l'*hypothesis space* est stable par scaling : si $h_{m}$ appartient à l'espace, $v_{m}.h_{m}$ appartient aussi à l'espace. Trouver le meilleur modèle $h_{m}$ comprend alors le calcul de $v_{m}$.\n",
    "* Tous les types de modèles de base ne sont pas forcément éligibles: il faut que leur combinaison linéaire soit capable d'approximer des fonctions plus complexes que ce qu'un modèle individuel est capable d'approcher. Ce n'est typiquement pas le cas des regressions linéaires. \n",
    "* On nuance la présentation du *boosting* commme mirroir du *bagging* qui laisse penser que le biais diminue avec une variance \"constante\". Il a toutefois été montré que pour certains types de modèles élémentaires fortements biaisés (KNN, *splines*), l'ajout d'un nouveau modèle diminue le biais avec une légère augmentation de la variance, le gain de biais compensant l'augmentation de variance. On nuance donc au passage la nécéssité que le modèle de base soit très fortement biaisé. Par exemple, les profondeurs d'arbres recommandées pour le *boosting* ont été progressivement revues à la hausse. \n",
    "\n",
    "## *Forward stagewise additive modeling* (FSAM)\n",
    "Une fois postulée la forme additive du modèle, celui-ci peut s'écrire comme la solution d'un problème d'optimisation:  \n",
    "\n",
    "$$f^{*} = \\underset{\\nu>0, h\\in\\mathcal{H}}{\\operatorname{argmin}} \\sum_{i=1}^{N} \\mathcal{L}(y_{i}, \\sum_{m=1}^{M} \\nu_{m}.h_{m}(x_{i}))$$\n",
    "\n",
    "Cette formulation (qui suppose $M$ fixé) dans laquelle on cherche à déterminer l'ensemble des composantes dans le même problème est en général insoluble. Le FSAM est un algorithme qui va chercher à approximer la fonction minimisant l'*empirical risk* en construisant séquentiellement une somme de modèles pris dans l'*hypothesis space* $\\mathcal{H}$, chaque nouveau modèle contribuant à faire décroitre la *loss* et nous rapprochant ainsi de la fonction réalisant le minimum. Dans ce contexte:\n",
    "* $h_i$ correspond à la direction dans laquelle on se déplace dans l'espace de fonction pour descendre la *loss* à l'étape $i$,\n",
    "* $v_i$ correspond à la *step size* du déplacement effectué dans l'espace de fonction à cette même étape.\n",
    "\n",
    "Remarque: L'espace de fonction dans lequel on se déplace est bien plus grand que l'*hypothesis space* $\\mathcal{H}$. Il inclut $\\mathcal{H}$ et nos déplacement dans l'espace de fonctions se font en restant dans $\\mathcal{H}$. \n",
    "\n",
    "Le FSAM consiste simplemement en l'algorithme suivant: \n",
    "* Initialiser $h_0=0$\n",
    "* A chaque étape $i\\in\\{0,\\dots,M\\}$:\n",
    "    * Calculer $(\\nu_i^*, h_i^*) = argmin_{\\nu>0, h\\in\\mathcal{H}}\\sum_j\\mathcal{L}(y_j, f_{i-1}(x_j)+\\nu h(x_j))$\n",
    "    * Updater le modèle d'ensemble: $f_i = f_{i-1}+\\nu_i^{*}.h_i^{*}$\n",
    "\n",
    "Remarque: $M$ est un hyperparamètre du modèle.\n",
    "\n",
    "### *Gradient boosting*\n",
    "Le *gradient boosting* nous donne une méthode pour déterminer la fonction à ajouter au modèle à chaque étape du FSAM pour une large gamme de *loss functions*, ces *loss functions* devant être simplement différentiables par rapport aux prédictions $f(x_i)$.\n",
    "\n",
    "A l'étape $m$ du FSAM, on cherche en effet $(\\nu_m^*, h_m^*)$ tels que:\n",
    "\n",
    "$$(\\nu_m^*, h_m^*) = argmin_{\\nu>0, h\\in\\mathcal{H}}\\sum_i\\mathcal{L}(y_i, f_{m-1}(x_i)+\\nu h(x_i))$$\n",
    "\n",
    "$h$ prenant ses valeurs dans un espace de fonction, c'est un problème d'optimisation difficile et potentiellement insoluble par une approche directe.\n",
    "\n",
    "L'idée consiste ne pas voir la fonction de coût $J(f)=\\sum_i\\mathcal{L}(y_i, f(x_i))$ comme dépendante de $f$ mais comme dépendant des prédictions $(f(x_1),\\dots,f(x_n))$. Après tout, $f$ n'est jamais évaluée que sur les point du *training set*. Si $\\mathcal{L}$ est différentiable par rapport aux prédictions $(f(x_1),\\dots,f(x_n))$, l'optimisation de $J$ sera plus simple car correspondra à une simple descente de gradient dans $\\mathbb{R}^n$. Dans cet espace de prédiction, chaque point correspond en fait à une fonction, s'y déplacer revient à se déplacer dans un espace de fonctions.\n",
    "\n",
    "Soit $g=\\nabla_{f(x_1),\\dots,f(x_n)}\\mathcal{L}$, on a par définition $f_m=f_{m-1}-\\nu_{m}.g$\n",
    "\n",
    "Toutefois, on ne peut pas utiliser directement $-g$ comme direction, $g$ n'ayant pas été contraint d'être dans l'*hypothesis space* $\\mathcal{H}$. On parle de $-g$ comme d'une *unconstrained direction*. $h_m$ sera donc la fonction de $\\mathcal{H}$ approchant le mieux $-g$. $g$ étant un vecteur de l'espace des prédiction, il correspond à des valeurs prises par une fonction sur le *training set*. Demander à une fonction de $\\mathcal{H}$ d'approcher $g$, cela revient à lui demander d'approcher les valeurs prises par une fonction sur le *training set*, on va donc *fitter* une fonction de $\\mathcal{H}$ sur $g$. Le modèle obtenu sera la meilleure approximation de $g$ dans $\\mathcal{H}$, son projeté orthogonal.\n",
    "\n",
    "Remarques:\n",
    "* On désigne parfois le *gradient boosting* sous le terme de *functional gradient descent* (FGD).\n",
    "* $\\nu_m$ peut être choisi par optimisation: on cherche le meilleur déplacement le long de la direction $g$: $\\nu_m = argmin_{\\nu>0}\\mathcal{L}(y,f_{m-1}-\\nu.g)$. En général, $\\nu$ est un hyperparamètre du modèle, de faibles valeurs (ex: 0.1) ayant un effet régularisant.\n",
    "* Le vecteur $-g$ est parfois appelé *pseudo-residuals* en référence au cas où $\\mathcal{L}$ est la *square error*: $\\mathcal{L}(y_i,f(x_i))=(y_i-f(x_i))^2$. Dans ce cas, on montre facilement qu'à l'étape $m$: $-g=2(y-f_{m-1})$, quantité correspondant aux résidus de l'étape $m-1$. Dit autrement, dans le cas où la *loss function* est la MSE, la construction du modèle par FSAM revient à trouver chaque nouveau modèle en l'entrainant sur les erreurs de l'ensemble précédent. Cette propriété particulière à cette *loss* est à l'origine de la présentation vulgarisée des modèles boostés consistant à expliquer qu'ils sont construits séquentiellement, chaque modèle ajouté venant corriger le modèle d'ensemble précédent (car entrainé sur ses erreurs).\n",
    "\n",
    "## Cas particuliers connus\n",
    "Adaboost: point de départ, algorithme proposé marche mais que pour cette loss qui n'a pas que des avantages (pondère très fortement les mauvaise marges, problématique si label noise)\n",
    "L2 boosting\n",
    "logitboost\n",
    "\n",
    "## Tuning\n",
    "Nombre d'itérations/de modèles individuels\n",
    "Profondeur des arbres\n",
    "Evaluation (online? out of bag)\n",
    "\n",
    "## Régularisation\n",
    "\n",
    "## Versions modernes: XGBoost, CatBoost, LightGBM\n",
    "\n",
    "L'idée générale est de trouver la fonction de la forme postulée (additive) minimisant la fonction de coût qu'on s'est choisi. Cette fonction est approchée à l'aide du FSAM. Il se trouve que pour un certain nombre de fonctions de coût répandues (MSE, MAE, exponential loss), l'algorithme FSAM peut être ramené à des problèmes qu'on sait résoudre (ex: l'algorithme Adaboost correspond à la construction d'un modèle par FSAM pour l'exponential loss) au moins approximativement (cf. cas où on trouve d'abord le modèle, puis le poids). A chacune de ces fonctions de coût correspond une méthode de résolution ad hoc mais l'utilisation du FSAM avec une fonction de coût quelconque ne semble pas évidente. On voudrait par exemple pouvoir fitter le meilleur modèle additif pour des fonctions de coût aux propriétés différentes. La MSE et l'exponential loss sont par exemple assez sensibles aux outliers mais la résolution du FSAM pour des fonctions de coût robustes peut apparaître assez peu trivial. C'est ce problème que veut résoudre le gradient boosting. \n",
    "$$\n",
    "L'idée du gradient boosting est de pouvoir trouver une solution (additive) approchée au problème de minimisation quelle que soit la fonction de coût pourvu que celle-ci soit différentiable par rapport à la prédiction. \n",
    "\n",
    "On peut voir l'addition de chaque fonction comme un déplacement dans l'espace de fonction : à chaque étape on se rapproche de la fonction à estimer, celle réalisant le minimum de la fonction de coût. Ce déplacement est en fait contraint à se faire dans un sous-espace tous les fonctions composant le modèle étant pris dans la \"même famille\". Contrairement à d'habitude, l'espace sur lequel on minimise la fonction de coût n'est pas un espace de paramètres ($\\mathbb{R^n}$) mais un espace de fonctions.\n",
    "\n",
    "Ce qui nous sauve de l'analyse fonctionnelle (problèmes topologiques de l'espace sur lequel on minimise, explicitation de l'incrément dans l'espace de fonctions, etc.) c'est que chaque fonction et donc la fonction de coût (l'erreur empirique) n'est évaluée que sur les $n$ points du *training set*. L'astuce consiste à optimiser la fonction de coût non pas directement par rapport à $f$ mais par rapport au vecteur de prédiction de taille $n$. La fonction de coût n'est alors à optimiser que sur $\\mathbb{R^n}$. On optimise comme souvent par descente de gradient. Chaque pas nous donne une nouvelle position dans l'espace des prédiction (correpondant à $\\mathbb{R^n}$). On parle ici d'*unconstrained direction* car la nouvelle prédiction obtenue ne fait aucune hypothèse particulière sur la fonction la réalisant. On se ramène ensuite alors à une fonction de la famille de modèles choisie en cherchant la meilleure fonction de cette famille approchant cette prédiction ce qui correspond à un simple problème de régression. Cela revient à chercher le projeté d'une fonction réalisant cette prédiction sur le sous-espace correspondant à notre famille de modèles.\n",
    "\n",
    "En régression et pour des *loss functions* comme la MSE ou MAE, il se trouve que la valeur à prédire permettant le meilleur décrément de la *loss function* à une étape donnée correspond aux résidus du modèle (complet) de l'étape précédente.\n",
    "\n",
    "Régularisation : \n",
    " * La principale technique de régularisation consiste à réduire la contribution de chaque modèle incrémental en le multipliant par un coefficient nu inférieur à 1 (cas qu'on peut interpréter comme réalisant en entier le déplacement dans l'espace des prédictions) souvent appelé shrinkage ou learning rate et pris égal à 0.1. Le modèle converge alors moins vite mais donne souvent de meilleurs résultats.\n",
    "* Une autre technique consiste à chaque étape à n'estimer la direction de meilleure diminution de la fonction de coût que sur une fraction (appelée parfois bag fraction) des données (subsampling). En plus de potentiellement accélerer l'entrainement, on peut interpréter sa propriété régularisante par le fait que les modèles ne voient pas toutes des données ce qui par rapport à leur donner l'intégralité doit aboutir à un modèle qui overfit moins. Appelé aussi mini-batch ou stochastic gradient boosting, cette technique peut se voir comme un subsampling des lignes. \n",
    "* Le subsampling des features (comme dans les random forests) est également utilisé par certains algorithmes comme XGBoost comme technique de régularisation. Cette technique peut se voir comme un subsampling des colonnes.\n",
    "* A cela peuvent s'ajouter des paramètres propres à la famille de modèles utilisée (ex: profondeur, taille des feuilles, etc. pour les arbres de décision)\n",
    "\n",
    "\n",
    "Adaboost \n",
    "Adaboost correspond à du gradient boosting appliqué au cas de l'exponential loss\n",
    "Un autre exemple de gradient boosting sur une autre loss function \n",
    "\n",
    "XGBoost, Catboost, LightGBM\n",
    "\n",
    "https://arxiv.org/pdf/1603.02754.pdf\n",
    "https://davidrosenberg.github.io/mlcourse/Archive/2018/Lectures/11b.gradient-boosting.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
